"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7785],{4718:(e,n,o)=>{o.d(n,{R:()=>a,x:()=>s});var i=o(3309);const r={},t=i.createContext(r);function a(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),i.createElement(t.Provider,{value:n},e.children)}},5750:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"infrastructure/azure/archive-data","title":"Archiving Data for Decommissioned Projects","description":"Best practices for data archiving","source":"@site/docs/infrastructure/azure/archive-data.md","sourceDirName":"infrastructure/azure","slug":"/infrastructure/azure/archive-data","permalink":"/dx/docs/infrastructure/azure/archive-data","draft":false,"unlisted":false,"editUrl":"https://github.com/pagopa/dx/tree/main/website/docs/infrastructure/azure/archive-data.md","tags":[],"version":"current","frontMatter":{"sidebar_label":"Archiving Data for Decommissioned Projects"},"sidebar":"tutorialSidebar","previous":{"title":"Verifying Online Service Reachability from an App Service Plan","permalink":"/dx/docs/infrastructure/azure/appservice-plan-dns-resolution"},"next":{"title":"Managing Azure IAM Roles and Permissions","permalink":"/dx/docs/infrastructure/azure/azure-iam"}}');var r=o(3881),t=o(4718);const a={sidebar_label:"Archiving Data for Decommissioned Projects"},s="Archiving Data for Decommissioned Projects",c={},l=[{value:"Best practices for data archiving",id:"best-practices-for-data-archiving",level:2},{value:"Recommended configuration for the destination storage account",id:"recommended-configuration-for-the-destination-storage-account",level:2},{value:"Sample Terraform configuration",id:"sample-terraform-configuration",level:3},{value:"Secondary region options",id:"secondary-region-options",level:3},{value:"Migrating from Azure Cosmos DB",id:"migrating-from-azure-cosmos-db",level:2},{value:"Migrating from another storage account",id:"migrating-from-another-storage-account",level:2},{value:"Blob storage migration",id:"blob-storage-migration",level:3},{value:"Object replication configuration with Terraform",id:"object-replication-configuration-with-terraform",level:4},{value:"Table storage migration",id:"table-storage-migration",level:3},{value:"Best practices and recommendations",id:"best-practices-and-recommendations",level:2},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"archiving-data-for-decommissioned-projects",children:"Archiving Data for Decommissioned Projects"})}),"\n",(0,r.jsx)(n.h2,{id:"best-practices-for-data-archiving",children:"Best practices for data archiving"}),"\n",(0,r.jsx)(n.p,{children:"When a project is decommissioned, it is important to strike a balance between\ndata retention for legal and auditing purposes and storage cost optimization.\nDepending on the context and specific requirements, adopting low-cost storage\nsolutions can be considered while ensuring access to the necessary information\nfor potential future audits. This guide provides a comprehensive approach to\ndata archiving with a focus on Azure storage solutions."}),"\n",(0,r.jsx)(n.h2,{id:"recommended-configuration-for-the-destination-storage-account",children:"Recommended configuration for the destination storage account"}),"\n",(0,r.jsx)(n.p,{children:"The optimal storage solution balances flexibility, support, and\ncost-effectiveness with the following characteristics:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Use archive storage tier"}),"\n",(0,r.jsx)(n.li,{children:"Disable internet access"}),"\n",(0,r.jsx)(n.li,{children:"Enforce authentication via Entra ID (disable access keys)"}),"\n",(0,r.jsx)(n.li,{children:"Implement legal hold policies"}),"\n",(0,r.jsx)(n.li,{children:"Configure multi-AZ replication in the primary region"}),"\n",(0,r.jsx)(n.li,{children:"Set up single-AZ replication in a secondary region"}),"\n",(0,r.jsx)(n.li,{children:"Enable object replication between regions"}),"\n",(0,r.jsx)(n.li,{children:"Apply read-only lock"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"sample-terraform-configuration",children:"Sample Terraform configuration"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-hcl",children:'resource "azurerm_storage_account" "backup_primary" {\n  name                = replace("${local.project}backupst01", "-", "")\n  resource_group_name = azurerm_resource_group.rg_itn_01.name\n  location            = local.location\n\n  account_kind             = "StorageV2"\n  account_tier             = "Standard"\n  account_replication_type = "ZRS"\n  access_tier              = "Cool"\n\n  public_network_access_enabled = false\n\n  shared_access_key_enabled       = false\n  default_to_oauth_authentication = true\n\n  blob_properties {\n    versioning_enabled       = true\n    change_feed_enabled      = true\n    last_access_time_enabled = true\n\n    delete_retention_policy {\n      days = 7\n    }\n\n    restore_policy {\n      days = 5\n    }\n\n    container_delete_retention_policy {\n      days = 10\n    }\n  }\n}\n'})}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Manually set the ",(0,r.jsx)(n.code,{children:"access_tier"})," to ",(0,r.jsx)(n.code,{children:"Archive"})," via Azure Portal after backup\ncompletion"]}),"\n",(0,r.jsxs)(n.li,{children:["Set ",(0,r.jsx)(n.code,{children:"public_network_access_enabled"})," to ",(0,r.jsx)(n.code,{children:"false"})," only after backup is complete"]}),"\n"]})}),"\n",(0,r.jsx)(n.h3,{id:"secondary-region-options",children:"Secondary region options"}),"\n",(0,r.jsx)(n.p,{children:"You can choose from the following regions for secondary storage:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Germany West Central (GWC)"}),"\n",(0,r.jsx)(n.li,{children:"Spain Central (SPC)"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"migrating-from-azure-cosmos-db",children:"Migrating from Azure Cosmos DB"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.a,{href:"https://github.com/AzureCosmosDB/data-migration-desktop-tool",children:"Azure Cosmos DB Data Migration Tool (DMT)"}),"\nis a command-line tool that can be used to migrate data between Azure Cosmos DB\nand other data sources."]}),"\n",(0,r.jsxs)(n.p,{children:["Download the release zip file, and edit the ",(0,r.jsx)(n.code,{children:"migrationsettings.json"})," according\nto the desired operation:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "Source": "Cosmos-nosql",\n  "Sink": "Json-AzureBlob",\n  "SourceSettings": {\n    "ConnectionString": "<cosmos-connection-string>",\n    "Database": "<cosmos-database-name>",\n    "Container": "<cosmos-container-name>",\n    "IncludeMetadataFields": true\n  },\n  "SinkSettings": {\n    "AccountEndpoint": "https://<storage-account-name>.blob.core.windows.net",\n    "ContainerName": "cosmosdb",\n    "BlobName": "<cosmos-container-name>",\n    "UseRbacAuth": true\n  }\n}\n'})}),"\n",(0,r.jsxs)(n.p,{children:["Then, run the ",(0,r.jsx)(n.code,{children:"dmt"})," executable file via CLI:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-sh",children:"chmod +x ./dmt\n./dmt\n"})}),"\n",(0,r.jsxs)(n.p,{children:["To restore data from the Azure Blob to Cosmos DB, modify the\n",(0,r.jsx)(n.code,{children:"migrationsettings.json"})," inverting the source and sink settings:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-json",children:'{\n  "Source": "Json-AzureBlob",\n  "Sink": "Cosmos-nosql",\n  "SourceSettings": {\n    "AccountEndpoint": "https://<storage-account-name>.blob.core.windows.net",\n    "ContainerName": "cosmosdb",\n    "BlobName": "<cosmos-container-name>",\n    "UseRbacAuth": true\n  },\n  "SinkSettings": {\n    "ConnectionString": "<cosmos-connection-string>",\n    "Database": "<cosmos-database-name>",\n    "Container": "<cosmos-container-name>",\n    "PartitionKeyPath": "/id"\n  }\n}\n'})}),"\n",(0,r.jsx)(n.h2,{id:"migrating-from-another-storage-account",children:"Migrating from another storage account"}),"\n",(0,r.jsx)(n.h3,{id:"blob-storage-migration",children:"Blob storage migration"}),"\n",(0,r.jsx)(n.p,{children:"The preferred method for migrating blobs between storage accounts is to use\nObject Replication Policy."}),"\n",(0,r.jsx)(n.p,{children:"It consists in an automatic asynchronous copy of all blobs in a Storage Account\ncontainer to another Storage Account. The target blob container becomes\nread-only when the policy is enabled."}),"\n",(0,r.jsx)(n.admonition,{type:"warning",children:(0,r.jsx)(n.p,{children:"You can't create cascading object replication policies on the same container.\nFor example, if there is already a policy replicating data from a container in\nstorage account A to a container in storage account B, you cannot create another\npolicy to replicate data from this container in storage account B to a container\nin storage account C."})}),"\n",(0,r.jsx)(n.h4,{id:"object-replication-configuration-with-terraform",children:"Object replication configuration with Terraform"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-hcl",children:'resource "azurerm_storage_object_replication" "old_to_new" {\n  source_storage_account_id      = azurerm_storage_account.old.id\n  destination_storage_account_id = azurerm_storage_account.new.id\n\n  rules {\n    source_container_name      = azurerm_storage_container.old1.name\n    destination_container_name = azurerm_storage_container.new1.name\n    copy_blobs_created_after   = "Everything"\n  }\n\n  rules {\n    source_container_name      = azurerm_storage_container.old2.name\n    destination_container_name = azurerm_storage_container.new2.name\n    copy_blobs_created_after   = "Everything"\n  }\n}\n'})}),"\n",(0,r.jsxs)(n.p,{children:["The property ",(0,r.jsx)(n.code,{children:"copy_blobs_created_after"})," accepts either ",(0,r.jsx)(n.code,{children:"Everything"})," or\n",(0,r.jsx)(n.code,{children:"OnlyNew"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"Everything"}),": This value ensures that all blobs in the source container,\nregardless of their creation date, are copied to the destination container.\nUse this option when you want a complete replication of all existing blobs."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"OnlyNew"}),": This value ensures that only blobs created after the replication\npolicy is applied are copied to the destination container. Use this option\nwhen you only need to replicate new blobs created after a certain point in\ntime. as values, but the former is advised as it ensures all blobs are copied."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"table-storage-migration",children:"Table storage migration"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"For small Tables:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Use\n",(0,r.jsx)(n.a,{href:"https://azure.microsoft.com/en-us/products/storage/storage-explorer#Download-4",children:"Microsoft Azure Storage Explorer"})]}),"\n",(0,r.jsxs)(n.li,{children:["Right-click source table and select ",(0,r.jsx)(n.code,{children:"Copy"})]}),"\n",(0,r.jsxs)(n.li,{children:["Right-click ",(0,r.jsx)(n.code,{children:"Tables"})," in destination storage account and select ",(0,r.jsx)(n.code,{children:"Paste"})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"For large Tables we recommend using Azure Data Factory pipelines"}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"best-practices-and-recommendations",children:"Best practices and recommendations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Always implement access controls"}),"\n",(0,r.jsx)(n.li,{children:"Use encryption at rest"}),"\n",(0,r.jsx)(n.li,{children:"Regularly audit archived data"}),"\n",(0,r.jsx)(n.li,{children:"Maintain a clear retention policy"}),"\n",(0,r.jsx)(n.li,{children:"Consider compliance requirements specific to your industry"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,r.jsx)(n.p,{children:"Effective data archiving requires a strategic approach that balances data\npreservation, security, and cost-efficiency. Regularly review and update your\narchiving strategy to ensure it meets your organization's evolving needs."})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}}}]);