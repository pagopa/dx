"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[3267],{4361:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/image-d63c66c98de2f172bbc873d1d73604e7.png"},4718:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>a});var i=t(3309);const s={},r=i.createContext(s);function o(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),i.createElement(r.Provider,{value:n},e.children)}},4750:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"articles/azure-tracing","title":"Integrating Tracing in Azure NodeJS Applications","description":"This guide covers the integration of Azure services with OpenTelemetry (OT) for","source":"@site/docs/articles/azure-tracing.md","sourceDirName":"articles","slug":"/articles/azure-tracing","permalink":"/dx/pr-preview/pr-518/docs/articles/azure-tracing","draft":false,"unlisted":false,"editUrl":"https://github.com/pagopa/dx/tree/main/website/docs/articles/azure-tracing.md","tags":[],"version":"current","frontMatter":{"sidebar_label":"Integrating Tracing in Azure NodeJS Applications"},"sidebar":"tutorialSidebar","previous":{"title":"Articles","permalink":"/dx/pr-preview/pr-518/docs/articles/"},"next":{"title":"Setting up Development Containers","permalink":"/dx/pr-preview/pr-518/docs/articles/setting-up-devcontainer"}}');var s=t(3881),r=t(4718);const o={sidebar_label:"Integrating Tracing in Azure NodeJS Applications"},a="Integrating Tracing in Azure NodeJS Applications",c={},l=[{value:"Azure and OpenTelemetry",id:"azure-and-opentelemetry",level:2},{value:"Patching native NodeJS fetch",id:"patching-native-nodejs-fetch",level:2},{value:"Instrument ESM applications",id:"instrument-esm-applications",level:2},{value:"Steps to Instrument an ESM Application",id:"steps-to-instrument-an-esm-application",level:3},{value:"Running the Instrumented Application",id:"running-the-instrumented-application",level:3},{value:"Use the <code>@pagopa/azure-tracing</code> Package",id:"use-the-pagopaazure-tracing-package",level:3},{value:"Using the Application Insights SDK",id:"using-the-application-insights-sdk",level:2},{value:"Enabling HTTP KeepAlive",id:"enabling-http-keepalive",level:2},{value:"Setting Sample Rate in AI SDK",id:"setting-sample-rate-in-ai-sdk",level:2},{value:"Using the <code>applicationinsights.json</code> configuration file",id:"using-the-applicationinsightsjson-configuration-file",level:3},{value:"Using the <code>APPLICATIONINSIGHTS_CONFIGURATION_CONTENT</code> environment variable",id:"using-the-applicationinsights_configuration_content-environment-variable",level:3},{value:"Set sample rate programmatically",id:"set-sample-rate-programmatically",level:3},{value:"Enable sampling of traces and custom events with OpenTelemetry",id:"enable-sampling-of-traces-and-custom-events-with-opentelemetry",level:2},{value:"Check if sampling is enabled",id:"check-if-sampling-is-enabled",level:2},{value:"Integration with App Services",id:"integration-with-app-services",level:2},{value:"Integration with Next.js Deployed on Azure App Service",id:"integration-with-nextjs-deployed-on-azure-app-service",level:3},{value:"Integration with Azure Functions",id:"integration-with-azure-functions",level:2},{value:"End-to-End tracing with host AI integration enabled",id:"end-to-end-tracing-with-host-ai-integration-enabled",level:3},{value:"Azure Function OpenTelemetry Instrumentation",id:"azure-function-opentelemetry-instrumentation",level:4},{value:"Align Sample Rate in AI SDK and Azure Functions Runtime",id:"align-sample-rate-in-ai-sdk-and-azure-functions-runtime",level:3},{value:"Configuring log levels for the Azure Functions runtime",id:"configuring-log-levels-for-the-azure-functions-runtime",level:3},{value:"Sampling gotchas within Azure Functions",id:"sampling-gotchas-within-azure-functions",level:3},{value:"End-to-End tracing with host AI integration disabled",id:"end-to-end-tracing-with-host-ai-integration-disabled",level:3},{value:"Setting Cloud Role Name",id:"setting-cloud-role-name",level:2},{value:"Sampling and Performance",id:"sampling-and-performance",level:2},{value:"Benchmark on App Service",id:"benchmark-on-app-service",level:3},{value:"Benchmark on Azure Functions",id:"benchmark-on-azure-functions",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Code Snippets",id:"code-snippets",level:2},{value:"Example Integration with App Service",id:"example-integration-with-app-service",level:3},{value:"Example of OT Context wrapper for Azure Functions",id:"example-of-ot-context-wrapper-for-azure-functions",level:3}];function d(e){const n={a:"a",admonition:"admonition",br:"br",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"integrating-tracing-in-azure-nodejs-applications",children:"Integrating Tracing in Azure NodeJS Applications"})}),"\n",(0,s.jsx)(n.p,{children:"This guide covers the integration of Azure services with OpenTelemetry (OT) for\ntracing NodeJS applications, along with benchmarking and performance insights."}),"\n",(0,s.jsx)(n.h2,{id:"azure-and-opentelemetry",children:"Azure and OpenTelemetry"}),"\n",(0,s.jsxs)(n.p,{children:["Microsoft is rapidly adopting ",(0,s.jsx)(n.strong,{children:"OpenTelemetry (OT)"})," as the standard for\ntracing, migrating from older custom solutions (e.g., vendor protocols for\n",(0,s.jsx)(n.strong,{children:"Application Insights"}),")."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"OpenTelemetry (OT)"})," is an open-source framework for collecting monitoring and\ntelemetry data, including traces, metrics, and logs, from software applications\nto improve observability and debugging."]}),"\n",(0,s.jsx)(n.p,{children:'The OT ecosystem for NodeJS consists of vendor-neutral libraries that enable a\nNodeJS process (whether on Azure or AWS) to send metrics to an OT "collector":'}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://github.com/open-telemetry/opentelemetry-js",children:"open-telemetry/opentelemetry-js: OpenTelemetry JavaScript Client"})}),"\n",(0,s.jsxs)(n.p,{children:["In the specific case of Azure, the collector is ",(0,s.jsx)(n.strong,{children:"Azure Monitor"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["The reference OT package for NodeJS in the Azure ecosystem is\n",(0,s.jsx)(n.a,{href:"https://www.npmjs.com/package/@azure/monitor-opentelemetry",children:"@azure/monitor-opentelemetry"}),",\nwhich exports a method ",(0,s.jsx)(n.code,{children:"useAzureMonitor"})," that enables the necessary\ninstrumentation for popular libraries (such as ",(0,s.jsx)(n.code,{children:"http"}),", ",(0,s.jsx)(n.code,{children:"redis"}),", ",(0,s.jsx)(n.code,{children:"mysql"}),",\n",(0,s.jsx)(n.code,{children:"postgresql"}),", etc.), so metrics can be transparently traced for users of\ndifferent SDK clients."]}),"\n",(0,s.jsxs)(n.p,{children:["OT instrumentation is implemented through runtime patching of the client SDK\ncalls. Therefore, you need to import the necessary libraries\n(",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"}),") and call the ",(0,s.jsx)(n.code,{children:"useAzureMonitor"})," method before\nincluding any other package in the codebase."]}),"\n",(0,s.jsx)(n.h2,{id:"patching-native-nodejs-fetch",children:"Patching native NodeJS fetch"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"})," package does not patch the native fetch\nmethod by default, which is commonly used in modern NodeJS applications."]}),"\n",(0,s.jsxs)(n.p,{children:["At the time of writing this document, instrumenting the native fetch of NodeJS\n(based on the undici package) requires an additional step on top of using the\n",(0,s.jsx)(n.code,{children:"useAzureMonitor"})," method:"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://github.com/Azure/azure-sdk-for-js/issues/29864",children:"Monitor OpenTelemetry - Add native fetch instrumentation"})}),"\n",(0,s.jsxs)(n.p,{children:["See\n",(0,s.jsx)(n.a,{href:"#example-integration-with-app-service",children:"Example Integration with App Service"}),"\nfor a complete example."]}),"\n",(0,s.jsxs)(n.admonition,{type:"warning",children:[(0,s.jsx)(n.p,{children:"If you are using version 2.x of the Application Insights SDK, be aware that it\ndoes not support instrumentation of the native fetch methods so external HTTP\nrequests will not be traced unless you use some custom fetch wrapper."}),(0,s.jsxs)(n.p,{children:["This is a further reason to migrate to the new version of the SDK (3.x) or to\nuse the ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"})," package."]})]}),"\n",(0,s.jsx)(n.h2,{id:"instrument-esm-applications",children:"Instrument ESM applications"}),"\n",(0,s.jsx)(n.p,{children:"Currently, there are some challenges with instrumenting ESM applications. While\nthe basic configuration enables data flow to Application Insights (visible on\nthe Azure Portal), end-to-end correlation does not function as expected."}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://github.com/open-telemetry/opentelemetry-js/tree/main/experimental/packages/opentelemetry-instrumentation#instrumentation-for-ecmascript-modules-esm-in-nodejs-experimental",children:"Instrumentation of ESM modules is still experimental"}),"\nand may not be as seamless as transpiling TypeScript to CommonJS modules.",(0,s.jsx)(n.br,{}),"\n",(0,s.jsx)(n.a,{href:"https://github.com/open-telemetry/opentelemetry-js/issues/4845#issuecomment-2253556217",children:"Inspired by a GitHub issue addressing a similar problem"}),", there\nis an alternative method to instrument the ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"}),"\npackage."]}),"\n",(0,s.jsx)(n.h3,{id:"steps-to-instrument-an-esm-application",children:"Steps to Instrument an ESM Application"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Create a new ",(0,s.jsx)(n.code,{children:".mjs"})," file, you can call it ",(0,s.jsx)(n.code,{children:"instrumentation.mjs"})," for example"]}),"\n",(0,s.jsx)(n.li,{children:"Add the following code to the beginning of the file:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:'import { createAddHookMessageChannel } from "import-in-the-middle";\nimport { register } from "module";\n\nconst { registerOptions, waitForAllMessagesAcknowledged } =\n  createAddHookMessageChannel();\n\nregister("import-in-the-middle/hook.mjs", import.meta.url, registerOptions);\n'})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Set up the instrumentation SDK you want to use:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"useAzureMonitor();\n"})}),"\n",(0,s.jsxs)(n.p,{children:["or in case you want to use the ",(0,s.jsx)(n.code,{children:"applicationinsights"})," SDK:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"appInsights.setup().start();\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This basic setup for both ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"})," and\n",(0,s.jsx)(n.code,{children:"applicationinsights"})," SDKs is enough to start sending telemetry data to Azure\nMonitor assuming the environment variable\n",(0,s.jsx)(n.code,{children:"APPLICATIONINSIGHTS_CONNECTION_STRING"})," is set up correctly."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Import the necessary instrumentations and register them"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"// If necessary, add other instrumentations, like the undici one\nregisterInstrumentations({\n  instrumentations: [instrumentAzureFunctions(), new UndiciInstrumentation()],\n  meterProvider: metrics.getMeterProvider(),\n  tracerProvider: trace.getTracerProvider(),\n});\n"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"At the end of the file, add the following code:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:"await waitForAllMessagesAcknowledged();\n"})}),"\n",(0,s.jsxs)(n.p,{children:["By following these steps, you can configure the ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"}),"\nor ",(0,s.jsx)(n.code,{children:"applicationinsights"})," package along with other instrumentations in an ESM\napplication."]}),"\n",(0,s.jsx)(n.h3,{id:"running-the-instrumented-application",children:"Running the Instrumented Application"}),"\n",(0,s.jsxs)(n.p,{children:["To ensure the instrumentation works correctly, you need to import the\n",(0,s.jsx)(n.code,{children:"instrumentation.mjs"})," file when running the application by using the\n",(0,s.jsx)(n.code,{children:"NODE_OPTIONS"})," environment variable:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'"NODE_OPTIONS": "--import ./dist/instrumentation.mjs",\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Ensure you use the correct path to the ",(0,s.jsx)(n.code,{children:"instrumentation.mjs"})," file, as it may\nvary depending on your project structure."]}),"\n",(0,s.jsx)(n.p,{children:"After setting everything up and running your application, you will see telemetry\ndata in Azure Monitor with service correlation:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"AI ESM E2E Tracing",src:t(7052).A+""})}),"\n",(0,s.jsxs)(n.h3,{id:"use-the-pagopaazure-tracing-package",children:["Use the ",(0,s.jsx)(n.code,{children:"@pagopa/azure-tracing"})," Package"]}),"\n",(0,s.jsxs)(n.p,{children:["To simplify the setup and avoid repetitive boilerplate, you can use the\n",(0,s.jsx)(n.code,{children:"@pagopa/azure-tracing"})," package.",(0,s.jsx)(n.br,{}),"\n","It provides a convenient wrapper around the ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"}),"\nlibrary, making instrumentation easier and more consistent."]}),"\n",(0,s.jsxs)(n.p,{children:["For usage details and examples, refer to the\n",(0,s.jsx)(n.a,{href:"https://www.npmjs.com/package/@pagopa/azure-tracing",children:"official documentation on npm"}),"."]}),"\n",(0,s.jsx)(n.admonition,{type:"warning",children:(0,s.jsxs)(n.p,{children:["Please note: until the package reaches a stable ",(0,s.jsx)(n.code,{children:"1.x"})," release, it is considered\nin beta.",(0,s.jsx)(n.br,{}),"\n","While we aim to keep the API stable, changes may occur as the package evolves."]})}),"\n",(0,s.jsx)(n.h2,{id:"using-the-application-insights-sdk",children:"Using the Application Insights SDK"}),"\n",(0,s.jsxs)(n.p,{children:["The latest version of the Application Insights SDK (3.x) is essentially a\nwrapper around OT functionalities provided by the ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"}),"\npackage:"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://github.com/microsoft/ApplicationInsights-node.js",children:"microsoft/ApplicationInsights-node.js: Microsoft Application Insights SDK for Node.js"})}),"\n",(0,s.jsxs)(n.p,{children:["The new AI SDK uses the ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"})," package under the hood:\nthe ",(0,s.jsx)(n.code,{children:"useAzureMonitor"})," method is called at the bootstrap of the application to\nenable tracing and metrics."]}),"\n",(0,s.jsxs)(n.p,{children:['Moreover, the SDK provides a series of\n"',(0,s.jsx)(n.a,{href:"https://github.com/microsoft/ApplicationInsights-node.js/tree/main/src/shim",children:"shims"}),'"\nthat enable its adoption in legacy applications using tracing methods from\nprevious versions (e.g., ',(0,s.jsx)(n.code,{children:"trackEvent"}),") without refactoring the existing code."]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["Although you can enable tracing and metrics using only the\n",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"})," package, if you want to use legacy AI methods\n(e.g., ",(0,s.jsx)(n.code,{children:"trackEvent"}),"), you must use the ",(0,s.jsx)(n.strong,{children:"AI SDK"})," and call the ",(0,s.jsx)(n.code,{children:"setup"})," and\n",(0,s.jsx)(n.code,{children:"start"})," methods at the bootstrap of the application to initialize the default\n",(0,s.jsx)(n.code,{children:"TelemetryClient"}),"."]})}),"\n",(0,s.jsxs)(n.p,{children:["Alternatively, you can use only ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"})," to send custom\nevents. To achieve this, ensure you are using version\n",(0,s.jsx)(n.a,{href:"https://github.com/Azure/azure-sdk-for-js/blob/main/sdk/monitor/monitor-opentelemetry-exporter/CHANGELOG.md#100-beta29-2025-03-04",children:"1.0.0-beta.29"}),"\nor later of the ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry-exporter"}),"."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import { useAzureMonitor } from "@azure/monitor-opentelemetry";\nimport { logs } from "@opentelemetry/api-logs";\n\nuseAzureMonitor(/* Add your Azure Monitor options here */);\n\n// ...\n\n// The logger name can be any string and is used to identify the logger\n// within log processors. This allows different processing rules to be applied,\n// enabling custom settings for sampling and log levels.\n\n// The AI SDK uses "ApplicationInsightsLogger" as the default logger name.\n// Refer to the source code here:\n// https://github.com/microsoft/ApplicationInsights-node.js/blob/03c380558f15fd46c20ba90de343e8d427f1be30/src/main.ts#L39\n// It is not mandatory to use the same name. However, if you do, the logger\n// will inherit the same configuration settings as the AI SDK.\n\nlogs.getLogger("ApplicationInsightsLogger").emit({\n  attributes: {\n    "microsoft.custom_event.name": "my-custom-event",\n    "foo": "bar",\n    ... // other custom attributes\n  },\n});\n'})}),"\n",(0,s.jsxs)(n.p,{children:["When evaluating to choose between the AI SDK and the Azure Monitor package,\nconsider that the AI SDK may fall behind new versions of\n",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"}),", so going with the latter may be more\nfuture-proof. The AI SDK is still advantageous if you need to use legacy AI\nmethods."]}),"\n",(0,s.jsx)(n.h2,{id:"enabling-http-keepalive",children:"Enabling HTTP KeepAlive"}),"\n",(0,s.jsxs)(n.admonition,{type:"note",children:[(0,s.jsx)(n.p,{children:"Unlike previous versions, HTTP KeepAlive is enabled by default in all modern\nAzure SDKs, and there is no longer a need to set up a custom agent."}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://github.com/Azure/azure-sdk-for-js/blob/main/sdk/core/core-rest-pipeline/src/pipelineRequest.ts#L149",children:"azure-sdk-for-js/sdk/core/core-rest-pipeline/src/pipelineRequest.ts"})})]}),"\n",(0,s.jsx)(n.h2,{id:"setting-sample-rate-in-ai-sdk",children:"Setting Sample Rate in AI SDK"}),"\n",(0,s.jsxs)(n.p,{children:["When using the AI SDK, it's a good practice to limit the number of traces sent\nto ",(0,s.jsx)(n.strong,{children:"Application Insights"})," by setting the sample rate."]}),"\n",(0,s.jsx)(n.p,{children:"The sample rate can be set in different ways."}),"\n",(0,s.jsxs)(n.h3,{id:"using-the-applicationinsightsjson-configuration-file",children:["Using the ",(0,s.jsx)(n.code,{children:"applicationinsights.json"})," configuration file"]}),"\n",(0,s.jsxs)(n.p,{children:["See\n",(0,s.jsx)(n.a,{href:"https://github.com/microsoft/ApplicationInsights-node.js?tab=readme-ov-file#configuration",children:"https://github.com/microsoft/ApplicationInsights-node.js?tab=readme-ov-file#configuration"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "samplingPercentage": 30\n}\n'})}),"\n",(0,s.jsxs)(n.h3,{id:"using-the-applicationinsights_configuration_content-environment-variable",children:["Using the ",(0,s.jsx)(n.code,{children:"APPLICATIONINSIGHTS_CONFIGURATION_CONTENT"})," environment variable"]}),"\n",(0,s.jsxs)(n.p,{children:["This environment variable takes precedence over the ",(0,s.jsx)(n.code,{children:"applicationinsights.json"}),"\nand has the same format as the JSON file."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'process.env["APPLICATIONINSIGHTS_CONFIGURATION_CONTENT"] =\n  process.env["APPLICATIONINSIGHTS_CONFIGURATION_CONTENT"] ??\n  JSON.stringify({\n    samplingPercentage: 5,\n  } satisfies Partial<IJsonConfig>);\n'})}),"\n",(0,s.jsx)(n.h3,{id:"set-sample-rate-programmatically",children:"Set sample rate programmatically"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'import * as ai from "applicationinsights";\n\nai.setup();\nai.defaultClient.config.samplingPercentage = 5;\nai.start();\n'})}),"\n",(0,s.jsx)(n.h2,{id:"enable-sampling-of-traces-and-custom-events-with-opentelemetry",children:"Enable sampling of traces and custom events with OpenTelemetry"}),"\n",(0,s.jsx)(n.p,{children:"OpenTelemetry uses Tracer and Loggers for different types of telemetry data:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"traces"}),": Used for traces (HTTP requests and other external calls) and\nmetrics."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"logs"}),": Used for console logs and custom events."]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"warning",children:(0,s.jsxs)(n.p,{children:["By design OpenTelemetry SDKs sample only ",(0,s.jsx)(n.em,{children:"traces"})," but not ",(0,s.jsx)(n.em,{children:"logs"}),"."]})}),"\n",(0,s.jsx)(n.p,{children:"In the context of Application Insights, the terminology differs:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"traces"}),": Correspond to logs emitted by the application using ",(0,s.jsx)(n.code,{children:"console.log"}),"\n(or ",(0,s.jsx)(n.code,{children:"context.log"})," in Azure Functions) and ",(0,s.jsx)(n.em,{children:"custom events"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"dependencies"}),": Correspond to Opentelemetry ",(0,s.jsx)(n.em,{children:"traces"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["To enable ",(0,s.jsx)(n.strong,{children:"parent based"})," sampling for ",(0,s.jsx)(n.em,{children:"logs"})," and ",(0,s.jsx)(n.em,{children:"custom events"}),", you can set\nthe following option when initializing the AI SDK ",(0,s.jsx)(n.em,{children:"before"})," calling ",(0,s.jsx)(n.code,{children:"ai.start()"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"ai.defaultClient.config.azureMonitorOpenTelemetryOptions = {\n  enableTraceBasedSamplingForLogs: true,\n};\n"})}),"\n",(0,s.jsxs)(n.p,{children:["This setting will ensure that ",(0,s.jsx)(n.em,{children:"logs"})," and ",(0,s.jsx)(n.em,{children:"custom events"})," are sampled based on\nthe parent trace context. Without this setting, ",(0,s.jsx)(n.em,{children:"logs"})," and ",(0,s.jsx)(n.em,{children:"custom events"})," will\nalways be forwarded at a 100% sample rate."]}),"\n",(0,s.jsx)(n.h2,{id:"check-if-sampling-is-enabled",children:"Check if sampling is enabled"}),"\n",(0,s.jsxs)(n.p,{children:["To check if sampling is enabled, you can use the following query in ",(0,s.jsx)(n.strong,{children:"Log\nAnalytics"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"union requests,dependencies,pageViews,browserTimings,exceptions,traces,customEvents\n| where timestamp > ago(1h)\n| summarize RetainedPercentage = 100/avg(itemCount) by bin(timestamp, 1m), itemType, sdkVersion\n"})}),"\n",(0,s.jsx)(n.p,{children:"Of course, you need to add a filter for the Azure Function or App Service\ninstance you are interested in."}),"\n",(0,s.jsx)(n.p,{children:"If you see values < 100 then sampling is enabled for that item type."}),"\n",(0,s.jsx)(n.h2,{id:"integration-with-app-services",children:"Integration with App Services"}),"\n",(0,s.jsxs)(n.p,{children:["Both ",(0,s.jsx)(n.strong,{children:"Azure Functions"})," and ",(0,s.jsx)(n.strong,{children:"App Services (NodeJS)"})," allow integration with\n",(0,s.jsx)(n.strong,{children:"Application Insights"})," without using the SDK. This integration is active in\nthe following scenarios:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["The legacy environment variable ",(0,s.jsx)(n.strong,{children:"APPINSIGHTS_INSTRUMENTATIONKEY"})," is set."]}),"\n",(0,s.jsxs)(n.li,{children:["The environment variable ",(0,s.jsx)(n.strong,{children:"APPLICATIONINSIGHTS_CONNECTION_STRING"})," is set."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["When either of these variables is set, the ",(0,s.jsx)(n.strong,{children:"NodeJS"})," application incorporates a\ncustom AI agent that starts at bootstrap before importing any other module."]}),"\n",(0,s.jsx)(n.admonition,{type:"warning",children:(0,s.jsx)(n.p,{children:"On App Services, this mechanism interferes with the programmatic setup of the AI\nSDK, overwriting its settings. Therefore, it is recommended to disable the\ndefault integration by removing these environment variables whether you are\nusing the AI SDK programmatically."})}),"\n",(0,s.jsxs)(n.p,{children:["When using the AI SDK, check that the default AI integration is disabled by\nensuring that the ",(0,s.jsx)(n.code,{children:"APPINSIGHTS_INSTRUMENTATIONKEY"})," and\n",(0,s.jsx)(n.code,{children:"APPLICATIONINSIGHTS_CONNECTION_STRING"})," variables are not set. It is recommended\nto use a custom environment variable that will be configured in the\n",(0,s.jsx)(n.code,{children:"useAzureMonitor"})," and/or ",(0,s.jsx)(n.code,{children:"ai.setup"})," settings."]}),"\n",(0,s.jsxs)(n.p,{children:["To verify that the default integration is indeed disabled, navigate to the\n",(0,s.jsx)(n.strong,{children:'"Application Insights"'})," panel of the App Service on the Azure portal."]}),"\n",(0,s.jsx)(n.p,{children:"At the time of writing, the default integration (agent) does not support\nend-to-end tracing which can be achieved only by using the AI SDK 3.x\nprogrammatically."}),"\n",(0,s.jsx)(n.h3,{id:"integration-with-nextjs-deployed-on-azure-app-service",children:"Integration with Next.js Deployed on Azure App Service"}),"\n",(0,s.jsxs)(n.p,{children:["For ",(0,s.jsx)(n.code,{children:"Next.js"})," applications deployed on ",(0,s.jsx)(n.strong,{children:"App Service"}),", similar considerations\napply. However, since there is no single entry point as with other frameworks,\nyou must use the ",(0,s.jsx)(n.strong,{children:"instrumentation module"}),". This module is loaded first by\n",(0,s.jsx)(n.strong,{children:"Next.js"})," to ensure that ",(0,s.jsx)(n.strong,{children:"Application Insights/OpenTelemetry"})," is initialized\nbefore anything else:"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://nextjs.org/docs/app/building-your-application/optimizing/open-telemetry#manual-opentelemetry-configuration",children:"https://nextjs.org/docs/app/building-your-application/optimizing/open-telemetry#manual-opentelemetry-configuration"})}),"\n",(0,s.jsxs)(n.p,{children:["It is possible to use the ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"})," package to instrument a\nNext.js application. However, in order to track the HTTP calls made by the\napplication, you need to use the ",(0,s.jsx)(n.code,{children:"undici"})," instrumentation. This instrumentation\nis not included in the ",(0,s.jsx)(n.code,{children:"@azure/monitor-opentelemetry"})," package, so you need to\nadd it manually.",(0,s.jsx)(n.br,{}),"\n","Here is a snippet to enable tracing in a Next.js application that uses the App\nrouter:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:'// apps/instrumentation.ts\n\nimport { useAzureMonitor } from "@azure/monitor-opentelemetry";\nimport { metrics, trace } from "@opentelemetry/api";\nimport { registerInstrumentations } from "@opentelemetry/instrumentation";\nimport { UndiciInstrumentation } from "@opentelemetry/instrumentation-undici";\n\nexport async function register() {\n  useAzureMonitor();\n\n  registerInstrumentations({\n    instrumentations: [new UndiciInstrumentation()],\n    meterProvider: metrics.getMeterProvider(),\n    tracerProvider: trace.getTracerProvider(),\n  });\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"integration-with-azure-functions",children:"Integration with Azure Functions"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Azure Functions"})," are a bit more complex to integrate with ",(0,s.jsx)(n.strong,{children:"OpenTelemetry"}),"\nsince you have to handle it both in the ",(0,s.jsx)(n.strong,{children:"Azure Functions"})," runtime (host) and\nin the application code (worker)."]}),"\n",(0,s.jsx)(n.h3,{id:"end-to-end-tracing-with-host-ai-integration-enabled",children:"End-to-End tracing with host AI integration enabled"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Azure Functions"})," runtime (host) activates monitoring when the\n",(0,s.jsx)(n.code,{children:"APPLICATIONINSIGHTS_CONNECTION_STRING"})," is set."]}),"\n",(0,s.jsxs)(n.admonition,{type:"warning",children:[(0,s.jsxs)(n.p,{children:["At the time of writing, only when activating OpenTelemetry\n(",(0,s.jsx)(n.code,{children:'"telemetryMode": "OpenTelemetry"'})," in host.json), the ",(0,s.jsx)(n.strong,{children:"Azure Functions"}),"\nruntime produces extraneous traces that are not part of the application code.\nThis behavior is expected to be fixed in the future:"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://github.com/Azure/azure-functions-host/issues/10770#issuecomment-2627874412",children:"https://github.com/Azure/azure-functions-host/issues/10770#issuecomment-2627874412"})})]}),"\n",(0,s.jsx)(n.p,{children:"In both configurations (OpenTelemetry enabled or disabled), when using the AI\n3.x SDK, you get end-to-end tracing of the application code (worker). Next step\nis align sample rate in AI SDK and Azure Functions runtime."}),"\n",(0,s.jsx)(n.h4,{id:"azure-function-opentelemetry-instrumentation",children:"Azure Function OpenTelemetry Instrumentation"}),"\n",(0,s.jsxs)(n.p,{children:["To enable end-to-end tracing in ",(0,s.jsx)(n.strong,{children:"Azure Functions"})," with OpenTelemetry, you need\nto add the related instrumentation to the worker code:"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://github.com/Azure/azure-functions-nodejs-opentelemetry",children:"https://github.com/Azure/azure-functions-nodejs-opentelemetry"})}),"\n",(0,s.jsx)(n.p,{children:"This instrumentation uses the Azure Function runtime (host) telemetry context to\npropagate it to the worker code. If you don't use this instrumentation, worker\ntraces will not be linked to the incoming HTTP request."}),"\n",(0,s.jsx)(n.p,{children:"At the time of writing, there is no way to disable verbose logging when using\nthis package:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://github.com/Azure/azure-functions-nodejs-opentelemetry/issues/8",children:"https://github.com/Azure/azure-functions-nodejs-opentelemetry/issues/8"})}),"\n",(0,s.jsxs)(n.p,{children:["Until this issue is resolved, it is recommended to extract and use only the part\nthat\n",(0,s.jsx)(n.a,{href:"https://github.com/Azure/azure-functions-nodejs-opentelemetry/blob/main/src/instrumentation.ts#L54",children:"enables end-to-end tracing"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["See ",(0,s.jsx)(n.a,{href:"#code-snippets",children:"Code Snippets"})," for the hook implementation that enables\nend-to-end tracing in Azure Functions."]}),"\n",(0,s.jsx)(n.h3,{id:"align-sample-rate-in-ai-sdk-and-azure-functions-runtime",children:"Align Sample Rate in AI SDK and Azure Functions Runtime"}),"\n",(0,s.jsx)(n.p,{children:"AI SDK use a fixed sample rate, while the Azure Functions runtime (host) uses an\nadaptive sampling mechanism. To minimize discrepancies in the number of traces\nrecorded, it is recommended to align the sample rate in the AI SDK with the\nAzure Functions runtime."}),"\n",(0,s.jsxs)(n.p,{children:["To align the sample rate in the Azure Functions runtime with the AI SDK, you can\nset these options in ",(0,s.jsx)(n.code,{children:"host.json"})," to the same value used programmatically:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "logging": {\n    "applicationInsights": {\n      "samplingSettings": {\n        "minSamplingPercentage": 5,\n        "maxSamplingPercentage": 5,\n        "initialSamplingPercentage": 5\n      }\n    }\n  }\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:"Alternatively, you may use the following environment variables for the same\npurpose:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"AzureFunctionsJobHost__logging__applicationInsights__samplingSettings__minSamplingPercentage=5\nAzureFunctionsJobHost__logging__applicationInsights__samplingSettings__maxSamplingPercentage=5\nAzureFunctionsJobHost__logging__applicationInsights__samplingSettings__initialSamplingPercentage=5\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Beware that the runtime also relies on the\n",(0,s.jsx)(n.code,{children:"AzureFunctionsJobHost__logging__applicationInsights__samplingSettings_maxTelemetryItemsPerSecond"}),"\nvariable to limit the number of traces sent, so perfect alignment cannot be\nguaranteed."]}),"\n",(0,s.jsx)(n.h3,{id:"configuring-log-levels-for-the-azure-functions-runtime",children:"Configuring log levels for the Azure Functions runtime"}),"\n",(0,s.jsxs)(n.p,{children:["The Azure Functions runtime (host) allows you to configure log levels for\ndifferent categories of logs. This configuration can be set in ",(0,s.jsx)(n.code,{children:"host.json"})," or\nusing environment variables."]}),"\n",(0,s.jsxs)(n.p,{children:["For example, to set the log level for ",(0,s.jsx)(n.code,{children:"Function"})," category to ",(0,s.jsx)(n.code,{children:"Information"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "logging": {\n    "logLevel": {\n      "Function": "Information"\n    }\n  }\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:"To set the same log level using environment variables instead:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"AzureFunctionsJobHost__logging__logLevel__Function=Information\n"})}),"\n",(0,s.jsx)(n.p,{children:"The latter approach is useful when you want to override the log level at runtime\nwithout redeploying the function app."}),"\n",(0,s.jsxs)(n.p,{children:["Setting the log level for the ",(0,s.jsx)(n.code,{children:"Function"})," category to ",(0,s.jsx)(n.code,{children:"Information"})," will generate\ntwo traces for ",(0,s.jsx)(n.em,{children:"each"})," function execution (e.g.,\n",(0,s.jsx)(n.code,{children:"Executed 'Functions.redis-fetch' (Succeeded, Id=d555444c-a409-4932-86a8-8c84d3777ba8, Duration=184ms)"}),")."]}),"\n",(0,s.jsxs)(n.p,{children:["While this can be useful for debugging and monitoring, it is not recommended for\nproduction as it can produce a ",(0,s.jsx)(n.em,{children:"large"})," number of traces. Note that setting this\nvalue to ",(0,s.jsx)(n.code,{children:"Warning"})," or higher will prevent ",(0,s.jsx)(n.code,{children:"context.log"})," and ",(0,s.jsx)(n.code,{children:"context.info"}),"\nmessages from being recorded in Application Insights. This is considered a\nreasonable trade-off since critical logs can still be captured using\n",(0,s.jsx)(n.code,{children:"context.warning"})," or ",(0,s.jsx)(n.code,{children:"context.error"}),", and the ",(0,s.jsx)(n.code,{children:"Information"})," level can be enabled\nfor debugging purposes when needed."]}),"\n",(0,s.jsxs)(n.p,{children:["The suggested approach is to set the default log level to ",(0,s.jsx)(n.code,{children:"Warning"})," or higher in\nproduction and use the AI SDK for custom events and logging:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "logging": {\n    "logLevel": {\n      "default": "Warning",\n      "Host.Results": "Information",\n      "Host.Aggregator": "Information"\n    }\n  }\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["This setup will ensure that only critical logs are recorded in Application\nInsights, while the AI SDK can be used for ",(0,s.jsx)(n.em,{children:"custom events"})," and to trace\n",(0,s.jsx)(n.em,{children:"exceptions"})," and ",(0,s.jsx)(n.em,{children:"warnings"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["Moreover, we keep the ",(0,s.jsx)(n.code,{children:"Host.Results"})," and ",(0,s.jsx)(n.code,{children:"Host.Aggregator"})," categories at\n",(0,s.jsx)(n.code,{children:"Information"})," to capture HTTP requests, function execution results and counters,\nuseful for monitoring and alerting."]}),"\n",(0,s.jsxs)(n.p,{children:["If capturing ",(0,s.jsx)(n.code,{children:"context.info"})," or ",(0,s.jsx)(n.code,{children:"context.log"})," is essential, you can set the log\nlevel for the specific ",(0,s.jsx)(n.code,{children:"Function"})," category to ",(0,s.jsx)(n.code,{children:"Information"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "logging": {\n    "logLevel": {\n      "Function.MyFunctionName.User": "Information"\n    }\n  }\n}\n'})}),"\n",(0,s.jsx)(n.p,{children:"Moreover, only for local debugging, you can set"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "logging": {\n    "logLevel": {\n      "Host.Function.Console": "Information"\n    }\n  }\n}\n'})}),"\n",(0,s.jsxs)(n.p,{children:["This will capture all ",(0,s.jsx)(n.code,{children:"console.log"})," messages locally, but they won't be sent to\nApplication Insights in production."]}),"\n",(0,s.jsxs)(n.p,{children:["Refer to ",(0,s.jsx)(n.a,{href:"https://github.com/anthonychu/functions-log-suppression",children:"https://github.com/anthonychu/functions-log-suppression"})," for more\ndetails."]}),"\n",(0,s.jsx)(n.h3,{id:"sampling-gotchas-within-azure-functions",children:"Sampling gotchas within Azure Functions"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Beware that ",(0,s.jsx)(n.code,{children:"traces"})," (logs) and ",(0,s.jsx)(n.code,{children:"customEvents"})," emitted by the AI SDK are not\nsampled. This implies that even if you configure a sample rate of 5% in the\nAI SDK, you will still see 100% of ",(0,s.jsx)(n.code,{children:"traces"})," and ",(0,s.jsx)(n.code,{children:"customEvents"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["When using ",(0,s.jsx)(n.code,{children:'"telemetryMode": "OpenTelemetry"'})," in ",(0,s.jsx)(n.code,{children:"host.json"}),", it appears that\nthere is no way to enable sampling at all for the host yet:\n",(0,s.jsx)(n.a,{href:"https://github.com/Azure/azure-functions-host/issues/10770#issuecomment-2629318006",children:"https://github.com/Azure/azure-functions-host/issues/10770#issuecomment-2629318006"})]}),"\n",(0,s.jsxs)(n.li,{children:["If you want to override ",(0,s.jsx)(n.code,{children:"logLevels"}),' using environment variables, beware that\n"',(0,s.jsx)(n.em,{children:"App settings that contain a period aren't supported when running on Linux\nin an Elastic Premium plan or a Dedicated (App Service) plan"}),'", see\n',(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/azure/azure-functions/configure-monitoring?tabs=v2#overriding-monitoring-configuration-at-runtime",children:"https://learn.microsoft.com/en-us/azure/azure-functions/configure-monitoring?tabs=v2#overriding-monitoring-configuration-at-runtime"})]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"end-to-end-tracing-with-host-ai-integration-disabled",children:"End-to-End tracing with host AI integration disabled"}),"\n",(0,s.jsxs)(n.p,{children:["If you choose to disable the default AI integration and rely solely on the AI\nSDK (using a variable other than ",(0,s.jsx)(n.code,{children:"APPLICATIONINSIGHTS_CONNECTION_STRING"}),"), you\nwill lose end-to-end tracing of the application code (worker) because the\nruntime (host) will no longer record HTTP requests."]}),"\n",(0,s.jsxs)(n.p,{children:["To achieve full integration and enable end-to-end tracing of calls in this\nscenario, you need to incorporate a wrapper around the Functions' handlers that\n",(0,s.jsx)(n.a,{href:"#example-of-ot-context-wrapper-for-azure-functions",children:"programmatically activates the OpenTelemetry mechanisms"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Benchmarks have shown that this wrapper does not introduce any significant\nperformance penalties, so you can safely use it in production."}),"\n",(0,s.jsx)(n.h2,{id:"setting-cloud-role-name",children:"Setting Cloud Role Name"}),"\n",(0,s.jsxs)(n.p,{children:["When using the AI SDK, the ",(0,s.jsx)(n.code,{children:"cloudRoleName"})," is set by default to the name of the\n",(0,s.jsx)(n.strong,{children:"App Service"})," or ",(0,s.jsx)(n.strong,{children:"Azure Function"}),". This value is used to identify the\nservice in ",(0,s.jsx)(n.strong,{children:"Application Insights"})," and group traces."]}),"\n",(0,s.jsxs)(n.p,{children:["If you need to customize the ",(0,s.jsx)(n.code,{children:"cloudRoleName"})," (the name of the service in\nApplication Insights), you can set the ",(0,s.jsx)(n.code,{children:"OTEL_SERVICE_NAME"})," environment."]}),"\n",(0,s.jsxs)(n.p,{children:["Setting a value for\n",(0,s.jsx)(n.code,{children:"ai.defaultClient.context.tags[ai.defaultClient.context.keys.cloudRole]"}),"\nproduces no result, even though some online tutorials suggest it. These\ntutorials are now considered obsolete."]}),"\n",(0,s.jsx)(n.h2,{id:"sampling-and-performance",children:"Sampling and Performance"}),"\n",(0,s.jsxs)(n.p,{children:["Load tests were performed on ",(0,s.jsx)(n.strong,{children:"App Service"})," and ",(0,s.jsx)(n.strong,{children:"Azure Functions"}),", with the\nfollowing conditions:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"AI completely disabled."}),"\n",(0,s.jsx)(n.li,{children:"AI enabled with sampling at 0%."}),"\n",(0,s.jsx)(n.li,{children:"AI enabled with sampling at 50%."}),"\n",(0,s.jsx)(n.li,{children:"AI enabled with sampling at 100%."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"benchmark-on-app-service",children:"Benchmark on App Service"}),"\n",(0,s.jsxs)(n.p,{children:["The test was conducted using ",(0,s.jsx)(n.strong,{children:"Azure Load Test"})," on a test App Service (B1) for\n5 minutes with an average of 200 requests per second. There was a maximum\noverhead of 30ms observed between tests with 100% sampling compared to those\nwith AI disabled."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"AI App Service Benchmark",src:t(4361).A+""})}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:"Using a sampling level < 30% introduces negligible overhead with AI enabled via\nSDK"})}),"\n",(0,s.jsx)(n.h3,{id:"benchmark-on-azure-functions",children:"Benchmark on Azure Functions"}),"\n",(0,s.jsxs)(n.p,{children:["The test was conducted on an ",(0,s.jsx)(n.strong,{children:"Azure Function"})," using the ",(0,s.jsx)(n.strong,{children:"Y1 consumption\nplan"})," for 5 minutes with an average of 200 requests per second. Once the\ninstances had scaled, a maximum overhead of 60ms was observed between tests with\n100% sampling and those with AI disabled."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"AI Functions Benchmark",src:t(6083).A+""})}),"\n",(0,s.jsx)(n.p,{children:"It seems that the sampling value had less impact on time differences once the\ninstances had scaled horizontally. However, the time needed for scaling\nincreased linearly with the sampling values."}),"\n",(0,s.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["It is recommended to start migrating logging and metric tracing procedures to\n",(0,s.jsx)(n.strong,{children:"OpenTelemetry"}),", incorporating the new version of the ",(0,s.jsx)(n.strong,{children:"AI SDK 3.x"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:["Adopting ",(0,s.jsx)(n.strong,{children:"OT"})," is currently the only method for achieving end-to-end\ntracing, including the tracing of native NodeJS fetch requests."]}),"\n",(0,s.jsx)(n.li,{children:"It is advisable to disable the default integrations and use the SDK\nprogrammatically on App Services."}),"\n",(0,s.jsxs)(n.li,{children:["The current OT implementation on ",(0,s.jsx)(n.strong,{children:"Azure Functions"})," is still unstable;\nmonitor progress and avoid using ",(0,s.jsx)(n.code,{children:'"telemetryMode": "OpenTelemetry"'})," in\nhost.json until issues are solved."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"code-snippets",children:"Code Snippets"}),"\n",(0,s.jsx)(n.h3,{id:"example-integration-with-app-service",children:"Example Integration with App Service"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:'import * as ai from "applicationinsights";\n\nimport { UndiciInstrumentation } from "@opentelemetry/instrumentation-undici";\nimport { registerInstrumentations } from "@opentelemetry/instrumentation";\nimport { metrics, trace } from "@opentelemetry/api";\nimport { IJsonConfig } from "applicationinsights/out/src/shim/types";\n\n// setup sampling percentage from environment (optional)\n// see https://github.com/microsoft/ApplicationInsights-node.js?tab=readme-ov-file#configuration\n// for other options. environment variable is in JSON format and takes\n// precedence over applicationinsights.json\nprocess.env["APPLICATIONINSIGHTS_CONFIGURATION_CONTENT"] =\n  process.env["APPLICATIONINSIGHTS_CONFIGURATION_CONTENT"] ??\n  JSON.stringify({\n    samplingPercentage: 30,\n  } satisfies Partial<IJsonConfig>);\n\n// setup cloudRoleName (optional)\nprocess.env.OTEL_SERVICE_NAME =\n  process.env.WEBSITE_SITE_NAME ?? "local-app-service";\n\nai.setup(process.env["AI_SDK_CONNECTION_STRING"]).start();\n\n// this must be called _after_ starting the AI SDK\n// in order to instantiate the OTEL tracer provider\nregisterInstrumentations({\n  tracerProvider: trace.getTracerProvider(),\n  meterProvider: metrics.getMeterProvider(),\n  // instrument native node fetch\n  instrumentations: [new UndiciInstrumentation({\n    requestHook: (span, requestInfo) => {\n      const { origin, method, path } = requestInfo;\n      // Default instrumented attributes don\'t feed well into AppInsights,\n      // so we set them manually.\n      span.setAttributes({\n        "http.url": `${origin}${path}`,\n        "http.method": method,\n        "http.target": path,\n        "http.host": origin,\n      });\n    },\n    responseHook: (span, { response }) => {\n      // Same as above, set the status code manually.\n      span.setAttribute("http.status_code", response.statusCode);\n    },\n  })],\n});\n//\n// Only when using Azure Function uncommented the code below\n//\n//  import { app } from "@azure/functions";\n//  import { context as otelContext, propagation } from \'@opentelemetry/api\';\n//\n// app.hook.preInvocation((context) => {\n//   const traceContext = context.invocationContext.traceContext;\n//   if (traceContext) {\n//     context.functionHandler = otelContext.bind(\n//       propagation.extract(otelContext.active(), {\n//         traceparent: traceContext.traceParent,\n//         tracestate: traceContext.traceState,\n//       }),\n//       context.functionHandler,\n//     );\n//   }\n// });\n//\nexport default ai;\n'})}),"\n",(0,s.jsx)(n.h3,{id:"example-of-ot-context-wrapper-for-azure-functions",children:"Example of OT Context wrapper for Azure Functions"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:'import { HttpRequest, InvocationContext, HttpHandler } from "@azure/functions";\nimport {\n  Attributes,\n  SpanKind,\n  SpanOptions,\n  SpanStatusCode,\n  TraceFlags,\n  context,\n  trace,\n  Span,\n  SpanContext,\n} from "@opentelemetry/api";\nimport {\n  SEMATTRS_HTTP_METHOD,\n  SEMATTRS_HTTP_STATUS_CODE,\n  SEMATTRS_HTTP_URL,\n} from "@opentelemetry/semantic-conventions";\n\nexport default function withAppInsights(func: HttpHandler) {\n  return async (req: HttpRequest, invocationContext: InvocationContext) => {\n    if (\n      process.env["DISABLE_FUNCTION_WRAPPER"]\n    ) {\n      return await func(req, invocationContext);\n    }\n    const startTime = Date.now();\n\n    // Extract the trace context from the incoming request\n    const traceParent = req.headers.get("traceparent");\n    const parts = traceParent?.split("-");\n\n    const parentSpanContext: SpanContext | null =\n      parts &&\n      parts.length === 4 &&\n      parts[1].length === 32 &&\n      parts[2].length === 16\n        ? {\n            traceId: parts[1],\n            spanId: parts[2],\n            traceFlags: TraceFlags.NONE,\n          }\n        : null;\n\n    const activeContext = context.active();\n\n    // Set span context as the parent context if any\n    const parentContext = parentSpanContext\n      ? trace.setSpanContext(activeContext, parentSpanContext)\n      : activeContext;\n\n    const attributes: Attributes = {\n      [SEMATTRS_HTTP_METHOD]: "HTTP",\n      [SEMATTRS_HTTP_URL]: req.url,\n    };\n\n    const options: SpanOptions = {\n      kind: SpanKind.SERVER,\n      attributes: attributes,\n      startTime: startTime,\n    };\n\n    // Emulates an HTTP request span\n    const span: Span = trace\n      .getTracer("ApplicationInsightsTracer")\n      .startSpan(`${req.method} ${req.url}`, options, parentContext);\n\n    let res;\n    try {\n      res = await context.with(trace.setSpan(activeContext, span), async () => {\n        return await func(req, invocationContext);\n      });\n      const status = res?.status;\n      if (status) {\n        span.setStatus({\n          code: status < 400 ? SpanStatusCode.OK : SpanStatusCode.ERROR,\n        });\n        span.setAttribute(SEMATTRS_HTTP_STATUS_CODE, status);\n      }\n    } catch (error) {\n      span.setStatus({\n        code: SpanStatusCode.ERROR,\n        message: error instanceof Error ? error.message : JSON.stringify(error),\n      });\n      throw error;\n    } finally {\n      span.end(Date.now());\n    }\n\n    return res;\n  };\n}\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",children:'app.http("root", {\n  route: "/",\n  methods: ["GET"],\n  authLevel: "anonymous",\n  handler: withAppInsights(async (req) => ({\n    body: `Hello, ${req.query.get("name")}!`,\n  })),\n});\n'})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},6083:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/image-1-6503f2cac9c69837b4c9d9287fe85c40.png"},7052:(e,n,t)=>{t.d(n,{A:()=>i});const i=t.p+"assets/images/ai-e2e-correlation-4e900d2c90485ba1dfda89db70a1be1e.png"}}]);